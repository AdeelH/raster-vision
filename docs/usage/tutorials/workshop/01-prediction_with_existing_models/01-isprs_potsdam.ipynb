{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee9e6787-94aa-494d-acbb-66752b19e82d",
   "metadata": {},
   "source": [
    "Running a PyTorch model over geospatial imagery\n",
    "===\n",
    "\n",
    "- QGIS, GeoTIFFs, GeoJSONs\n",
    "- AWS S3\n",
    "- PyTorch\n",
    "- Raster Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0317353d-dd02-4d74-8631-5ee89ac6b33f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea79636-e84e-487d-87b0-25e5d9fb3bff",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c684167a-f27c-4371-af2f-f58fc1550557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade ipympl ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a5cb78-9e25-4999-b186-752ba599b958",
   "metadata": {},
   "source": [
    "We will be accessing files on S3 in this notebook. Since those files are public, we set the `AWS_NO_SIGN_REQUEST` to tell `rasterio` to skip the sign-in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73747ce-cd2f-4f23-9fe9-69dfd8516f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env AWS_NO_SIGN_REQUEST=YES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99c5038-4b3b-4cb9-b838-85c4046f437c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0796e4-df9b-4ee4-89ef-5533c1bd399b",
   "metadata": {},
   "source": [
    "# GeoTIFFs and S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c2d8de-f1a0-4617-b105-7f6f2244c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = 's3://azavea-research-public-data/raster-vision/examples/sample_images/sample-img-isprs-potsdam-ss.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daa60ba-6bd6-4d7e-9b18-7765b99573dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {image_uri} data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6613dd4-9cbb-45b1-8a97-7273d66a3566",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24faf63-a1b0-442c-86f2-c6aafe8dabd5",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bccb38-9bea-44de-95ab-0c94954cfe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rastervision.core.data import ClassConfig\n",
    "\n",
    "class_config = ClassConfig(\n",
    "    names=['Car', 'Building', 'Low Vegetation', 'Tree', 'Impervious', 'Clutter', 'null'],\n",
    "    colors=['#ffff00', '#0000ff', '#00ffff', '#00ff00', '#ffffff', '#ff0000', '#000000'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6bbffe-7551-4a6b-95a2-7f8cdd3adeba",
   "metadata": {},
   "source": [
    "## Architecture and weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b0d75e-79ec-4c11-acb8-7a368d631048",
   "metadata": {},
   "source": [
    "The model architecture we are using here is a [panoptic FPN](https://arxiv.org/abs/1901.02446) with a [ResNet-18](https://arxiv.org/abs/1512.03385) backbone\n",
    "\n",
    "The particular implementation we are using is from this repo: https://github.com/AdeelH/pytorch-fpn\n",
    "\n",
    "Note how we use [TorchHub](https://pytorch.org/docs/stable/hub.html) to load the model from a GitHub repo. You can use it to pull model implementations from any repo that has a `hubconf.py` in its root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d09bc5a-7644-478c-a6b3-83b3aca13dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load(\n",
    "    # github tag\n",
    "    'AdeelH/pytorch-fpn:0.3',\n",
    "    # entrypoint i.e. function defined in the repo that creates the model\n",
    "    'make_fpn_resnet',\n",
    "    # everything below is arguments passed to the entrypoint\n",
    "    name='resnet50',\n",
    "    fpn_type='panoptic',\n",
    "    num_classes=len(class_config),\n",
    "    fpn_channels=256,\n",
    "    in_channels=3,\n",
    "    out_size=(256, 256),\n",
    "    pretrained=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e8d270-c203-4e84-bdf5-312357939eb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55511454-6f11-483b-996d-12665b5fcf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "first_conv_layer = model[0].m[0][0].weight.cpu()\n",
    "grid = make_grid(first_conv_layer, normalize=True)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.imshow(grid.permute(1, 2, 0))\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b61789-e38a-4940-bcd4-38c917c1b518",
   "metadata": {},
   "source": [
    "### Load trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc3bc1-3219-4026-abe1-ccf633f5402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rastervision.pipeline.file_system.utils import download_if_needed\n",
    "\n",
    "model_weights_uri = 's3://azavea-research-public-data/raster-vision/examples/model-zoo-0.30/isprs-potsdam-ss/train/last-model.pth'\n",
    "model_weights_path = download_if_needed(model_weights_uri)\n",
    "model.load_state_dict(torch.load(model_weights_path, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed82c877-c309-4e2a-9e24-d75f8fc099df",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_conv_layer = model[0].m[0][0].weight.cpu()\n",
    "grid = make_grid(first_conv_layer, normalize=True)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.imshow(grid.permute(1, 2, 0))\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f09ecf-5b1b-4826-b370-a9be65a5c82b",
   "metadata": {},
   "source": [
    "### Counting params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af6a1b6-dbde-4429-ba3d-dd5d83ae997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#params: ', f'{sum(p.numel() for p in model.parameters()):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45acda96-40c6-4981-b540-8d265dcbc24a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7d9c39-d701-4de4-b45b-7461ead9ba43",
   "metadata": {},
   "source": [
    "# Predicting in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b063b6-77f1-4fce-a5a7-72d9bab6c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rastervision.pytorch_learner import SemanticSegmentationSlidingWindowGeoDataset\n",
    "\n",
    "ds = SemanticSegmentationSlidingWindowGeoDataset.from_uris(\n",
    "    class_config=class_config,\n",
    "    image_uri=image_uri,\n",
    "    image_raster_source_kw=dict(channel_order=[0, 1, 2]),\n",
    "    size=300,\n",
    "    stride=300,\n",
    "    out_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86c9678-715e-483c-9dfb-dca87441a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ds.scene.raster_source[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce5151-d447-4d18-96f2-f76ad766ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "from matplotlib import animation\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "windows = list(sorted(ds.windows, key=lambda w: tuple(w)))\n",
    "\n",
    "def data_gen():\n",
    "    for i in range(40):\n",
    "        yield i\n",
    "\n",
    "def draw(i):\n",
    "    ax.clear()\n",
    "    ax.imshow(img)\n",
    "    for w in windows[:i]:\n",
    "        p = patches.Polygon(w.to_points(), color='darkred', fill=False)\n",
    "        ax.add_patch(p)\n",
    "    w = windows[i]\n",
    "    p = patches.Polygon(w.to_points(), color='r', lw=2, fill=False)\n",
    "    ax.add_patch(p)\n",
    "    return [ax]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, draw, data_gen, repeat=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892fc32-a059-431a-ab97-3278789c61ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rastervision.pytorch_learner import (\n",
    "    DataConfig, SemanticSegmentationLearner, SemanticSegmentationLearnerConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b42ed1d-a106-48fc-b9ba-8cf03b6f22fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = SemanticSegmentationLearner(\n",
    "    cfg=SemanticSegmentationLearnerConfig(\n",
    "        data=DataConfig(class_config=class_config, img_sz=256)),\n",
    "    model=model,\n",
    "    training=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc4db4-f927-4ed7-91d5-277d559eb140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rastervision.core.data import SemanticSegmentationLabels\n",
    "\n",
    "predictions = learner.predict_dataset(\n",
    "    ds,\n",
    "    raw_out=True,\n",
    "    numpy_out=True,\n",
    "    predict_kw=dict(out_shape=(300, 300)),\n",
    ")\n",
    "\n",
    "pred_labels = SemanticSegmentationLabels.from_predictions(\n",
    "    ds.windows,\n",
    "    predictions,\n",
    "    smooth=True,\n",
    "    extent=ds.scene.extent,\n",
    "    num_classes=len(class_config),\n",
    "    crop_sz=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a06045e-ce55-4891-90f2-86ad4ed8900d",
   "metadata": {},
   "source": [
    "# Visualizing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc41fef-4d6a-4fca-9a71-d809fbb6b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pred_labels.get_score_arr(pred_labels.extent)\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7024d7b-9bbf-4a01-94c7-ec7d22ec068b",
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig, axs = plt.subplots(2, 3, figsize=(9, 6))\n",
    "for i, (ax, class_name) in enumerate(zip(axs.flat, class_config.names[:6])):\n",
    "    fig.tight_layout(w_pad=-2)\n",
    "    ax.imshow(scores[i], cmap='plasma')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(class_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43f762f-0671-41ba-98fe-94fe13c15939",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels.save(\n",
    "    uri='data/isprs_potsdam/predictions_1/',\n",
    "    crs_transformer=ds.scene.raster_source.crs_transformer,\n",
    "    class_config=class_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7b3eb8-f641-4dd5-9110-7528d44bb963",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9725591f-fcb9-4bbd-9095-06dad514eace",
   "metadata": {},
   "source": [
    "# Smoothing out edge artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74baf81b-0aa9-4b4c-81e5-533a1bbd10c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SemanticSegmentationSlidingWindowGeoDataset.from_uris(\n",
    "    class_config=class_config,\n",
    "    image_uri=image_uri,\n",
    "    image_raster_source_kw=dict(channel_order=[0, 1, 2]),\n",
    "    size=300,\n",
    "    stride=150,\n",
    "    out_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a5eaa2-c70d-400a-b06e-e9f48613176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_sz = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296fccd0-6f12-43fa-a71d-a91a262241c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "windows = list(sorted(ds.windows, key=lambda w: tuple(w)))\n",
    "\n",
    "def data_gen():\n",
    "    for i in range(60):\n",
    "        yield i\n",
    "\n",
    "def draw(i):\n",
    "    ax.clear()\n",
    "    ax.imshow(img)\n",
    "    for w in windows[:i]:\n",
    "        p = patches.Polygon(w.to_points(), color='black', fill=False)\n",
    "        ax.add_patch(p)\n",
    "        w = w.center_crop(crop_sz, crop_sz)\n",
    "        p = patches.Polygon(w.to_points(), color='darkred', fill=False)\n",
    "        ax.add_patch(p)\n",
    "    w = windows[i]\n",
    "    w = w.center_crop(crop_sz, crop_sz)\n",
    "    p = patches.Polygon(w.to_points(), color='r', lw=2, fill=False)\n",
    "    ax.add_patch(p)\n",
    "    return [ax]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, draw, data_gen, repeat=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74e6295-096a-49cb-b43c-983473e70604",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = learner.predict_dataset(\n",
    "    ds,\n",
    "    raw_out=True,\n",
    "    numpy_out=True,\n",
    "    predict_kw=dict(out_shape=(300, 300)),\n",
    ")\n",
    "\n",
    "pred_labels = SemanticSegmentationLabels.from_predictions(\n",
    "    ds.windows,\n",
    "    predictions,\n",
    "    smooth=True,\n",
    "    extent=ds.scene.extent,\n",
    "    num_classes=len(class_config),\n",
    "    crop_sz=crop_sz,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbb1a84-0f01-4dc1-ada4-690102a0d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pred_labels.get_score_arr(pred_labels.extent)\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fef892-f99b-466e-9fad-303d0b46004b",
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig, axs = plt.subplots(2, 3, figsize=(9, 6))\n",
    "for i, (ax, class_name) in enumerate(zip(axs.flat, class_config.names[:6])):\n",
    "    fig.tight_layout(w_pad=-2)\n",
    "    ax.imshow(scores[i], cmap='plasma')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(class_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a4e538-3d2f-4614-b22c-8254fb901085",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels.save(\n",
    "    uri='data/isprs_potsdam/predictions_2/',\n",
    "    crs_transformer=ds.scene.raster_source.crs_transformer,\n",
    "    class_config=class_config,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
